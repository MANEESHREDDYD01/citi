{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42688eda-233f-4148-b807-93aaad574c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from prophet import Prophet\n",
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8421cc63-3622-40ca-8322-47e802e85086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 2] No such file or directory: '/Users/sree/Documents/CDA/Project_1/sp25_taxi-main/data/processed'\n"
     ]
    }
   ],
   "source": [
    "# Load time series data from a Parquet file\n",
    "def load_data(parquet_path):\n",
    "    \"\"\"Loads time series data from a Parquet file.\"\"\"\n",
    "    df = pd.read_parquet(parquet_path, engine='pyarrow')\n",
    "    print(\"Columns in dataset:\", df.columns)  # Debugging: Print available columns\n",
    "    return df\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(df, location_id=43):\n",
    "    \"\"\"Filters data for a specific location and ensures a time series format.\"\"\"\n",
    "    if \"pickup_datetime\" not in df.columns:\n",
    "        raise KeyError(\"Column 'pickup_datetime' not found in dataset. Available columns: \" + str(df.columns))\n",
    "    \n",
    "    df[\"pickup_hour\"] = pd.to_datetime(df[\"pickup_datetime\"]).dt.floor(\"h\")  # Convert datetime to hourly\n",
    "    df = df[df[\"pickup_location_id\"] == location_id]\n",
    "    df = df.sort_values(\"pickup_hour\")\n",
    "    df = df.set_index(\"pickup_hour\")\n",
    "    \n",
    "    # Use only the last 6 months of data to improve recent trends\n",
    "    six_months_ago = df.index.max() - pd.DateOffset(months=6)\n",
    "    df = df[df.index >= six_months_ago]\n",
    "    \n",
    "    # Resample to ensure all hourly timestamps are present, filling missing values with 0\n",
    "    ts_data = df[\"pickup_location_id\"].resample(\"H\").count().reset_index()\n",
    "    ts_data.columns = [\"ds\", \"y\"]  # Prophet requires columns named 'ds' and 'y'\n",
    "    \n",
    "    return ts_data\n",
    "\n",
    "# Generate FFT-based features efficiently\n",
    "def generate_fft_features(ts_data, variance_threshold=0.95):\n",
    "    \"\"\"Computes FFT and extracts top frequency components based on variance threshold.\"\"\"\n",
    "    y_fft = fft(ts_data[\"y\"])\n",
    "    freqs = np.fft.fftfreq(len(ts_data))\n",
    "    df_fft = pd.DataFrame({\"frequency\": freqs, \"amplitude\": np.abs(y_fft)})\n",
    "    \n",
    "    # Select frequencies that contribute to 95% variance\n",
    "    df_fft = df_fft.sort_values(by=\"amplitude\", ascending=False)\n",
    "    total_variance = df_fft[\"amplitude\"].sum()\n",
    "    df_fft[\"cumulative_variance\"] = df_fft[\"amplitude\"].cumsum() / total_variance\n",
    "    df_fft = df_fft[df_fft[\"cumulative_variance\"] <= variance_threshold]\n",
    "    \n",
    "    # Efficiently create FFT feature matrix\n",
    "    fft_features = np.array([np.sin(2 * np.pi * row[\"frequency\"] * np.arange(len(ts_data))) * row[\"amplitude\"] for _, row in df_fft.iterrows()]).T\n",
    "    fft_feature_cols = [f\"fft_{i}\" for i in range(fft_features.shape[1])]\n",
    "    fft_df = pd.DataFrame(fft_features, columns=fft_feature_cols)\n",
    "    \n",
    "    # Concatenate efficiently to avoid fragmentation\n",
    "    ts_data = pd.concat([ts_data, fft_df], axis=1)\n",
    "    return ts_data\n",
    "\n",
    "# Apply PCA for feature selection\n",
    "def apply_pca(ts_data, n_components=5):\n",
    "    \"\"\"Reduces the dimensionality of FFT features using PCA.\"\"\"\n",
    "    feature_cols = [col for col in ts_data.columns if col.startswith(\"fft_\")]\n",
    "    if len(feature_cols) > 0:\n",
    "        scaler = StandardScaler()\n",
    "        pca = PCA(n_components=min(n_components, len(feature_cols)))\n",
    "        transformed_features = pca.fit_transform(scaler.fit_transform(ts_data[feature_cols]))\n",
    "        \n",
    "        for i in range(transformed_features.shape[1]):\n",
    "            ts_data[f\"pca_fft_{i}\"] = transformed_features[:, i]\n",
    "        \n",
    "        ts_data.drop(columns=feature_cols, inplace=True)  # Remove raw FFT features\n",
    "    \n",
    "    return ts_data\n",
    "\n",
    "# Fit Prophet model\n",
    "def fit_prophet_model(ts_data):\n",
    "    \"\"\"Fits a Prophet model to the time series data including FFT-PCA features.\"\"\"\n",
    "    model = Prophet(changepoint_prior_scale=0.05, yearly_seasonality=False, weekly_seasonality=True, daily_seasonality=True)\n",
    "    for col in ts_data.columns:\n",
    "        if col.startswith(\"pca_fft_\"):\n",
    "            model.add_regressor(col)\n",
    "    model.fit(ts_data)\n",
    "    return model\n",
    "\n",
    "# Forecast future values\n",
    "def forecast_prophet_model(model, ts_data, steps=10):\n",
    "    \"\"\"Generates forecasts using the fitted Prophet model.\"\"\"\n",
    "    future = model.make_future_dataframe(periods=steps, freq='H')\n",
    "    for col in ts_data.columns:\n",
    "        if col.startswith(\"pca_fft_\"):\n",
    "            future[col] = ts_data[col].mean()\n",
    "    forecast = model.predict(future)\n",
    "    return forecast.tail(steps)[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]]\n",
    "\n",
    "# Calculate MAE\n",
    "def calculate_mae(actual, forecasted):\n",
    "    \"\"\"Calculates the Mean Absolute Error (MAE) between actual and forecasted values.\"\"\"\n",
    "    return mean_absolute_error(actual, forecasted)\n",
    "\n",
    "# Plot actual and forecasted values\n",
    "def plot_forecast(ts_data, forecast):\n",
    "    \"\"\"Plots actual data and forecasted values with confidence intervals.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(ts_data[\"ds\"], ts_data[\"y\"], label=\"Actual Data\", color='blue')\n",
    "    plt.plot(forecast[\"ds\"], forecast[\"yhat\"], label=\"Forecast\", linestyle='dashed', color='red')\n",
    "    plt.fill_between(forecast[\"ds\"], forecast[\"yhat_lower\"], forecast[\"yhat_upper\"], color='pink', alpha=0.3, label=\"95% Confidence Interval\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Ride Counts\")\n",
    "    plt.title(\"Optimized Prophet Forecast with FFT-PCA Features\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define file path\n",
    "    parquet_file_path = \"/Users/sree/Documents/CDA/Project_1/sp25_taxi-main/data/processed\"  # Update with actual path\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    try:\n",
    "        ts_df = load_data(parquet_file_path)\n",
    "        ts_series = preprocess_data(ts_df)\n",
    "        ts_series = generate_fft_features(ts_series)  # Extract FFT-based features efficiently\n",
    "        ts_series = apply_pca(ts_series)  # Apply PCA for better feature selection\n",
    "    \n",
    "        # Fit Prophet model\n",
    "        prophet_model = fit_prophet_model(ts_series)\n",
    "    \n",
    "        # Forecast the next 10 time steps\n",
    "        forecast_values = forecast_prophet_model(prophet_model, ts_series, steps=10)\n",
    "    \n",
    "        # Calculate and print MAE\n",
    "        mae = calculate_mae(ts_series[\"y\"].tail(10), forecast_values[\"yhat\"])\n",
    "        print(f\"Optimized Prophet Model with FFT-PCA Features MAE: {mae:.4f}\")\n",
    "    \n",
    "        # Print forecasts\n",
    "        print(\"Forecasted Values:\")\n",
    "        print(forecast_values)\n",
    "    \n",
    "        # Plot actual vs forecasted values\n",
    "        plot_forecast(ts_series, forecast_values)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
